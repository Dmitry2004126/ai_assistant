# ai_assistant
Прокси-сервер для работы с LLM. 

Данный сервис предлагает возможность задать любой вопрос LLM
и через несколько секунд получить ответ на свой вопрос.
Доступна функция просмотра последних 10 сообщений и вопросов.

## Структура проекта

```
app/                    # <-- Исходники приложения
├── api/                # <-- API приложения
│   ├── endpoints/      # <-- Эндпоинты
│   └── routers.py      # <-- Все роутеры приложения
├── core/               # <-- Ядро приложения
│   ├── auth/           # <-- Авторизация/Регистрация
│   ├── docs/           # <-- Исправления для swagger
│   ├── logs/           # <-- Логирование приложения
│   ├── middleware/     # <-- Middleware приложения
│   ├── base.py         # <-- Импорты класса Base и всех моделей для Alembic
│   ├── config.py       # <-- Все конфиги и константы проекта
│   ├── db.py           # <-- Настройка соединения с БД
│   └── enums.py        # <-- Все emun перечисления приложения
├── crud/               # <-- Вся логика взаимодействия с БД
├── models/             # <-- Модели SQLAlchemy
├── schemas/            # <-- Схемы Pydantic
├── services/           # <-- Папка для бизнес-логики
├── tests/              # <-- Папка с тестами
└── main.py             # <-- Точка входа в приложение
```



## Инструкция:

В корне лежит файл `.env.template` (пример).

- для запуска локально нужен файл `.env`


## Запуск локально:

Для начала проверьте, что у вас установен uv
```sh
 uv --version
```

Установка зависимостей

```sh
uv sync
```

Запуск приложения

```sh
uv run uvicorn app.main:app --host localhost --port 8000  --reload
```

## Запуск Docker контейнера:
Для запуска контейнера нужно создать базу данных и указать файл с переменными окружения для сервиса.
```sh
docker build -t my-app .
docker run -p 8000:8000 --env-file .env my-app
```

Документация Swagger будет доступна по адресу localhost:8000/docs

## Запуск тестов (pytest):
```sh
pytest
```
